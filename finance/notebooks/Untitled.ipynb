{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3623cafc-a4e4-4fc1-899d-114bd1714ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv ,time ,re ,os ,json ,requests\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime ,timedelta\n",
    "\n",
    "import urllib3\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "class catcher() :\n",
    "    def __init__( self ,since ,until ,base_dir=None ,wait_time=2 ) :\n",
    "        self.csv_tag = [ 'id' ,'title' ,'url' ,'code' ,'update' ]\n",
    "        self.encode_type = 'utf-8'\n",
    "        self.wait_time = wait_time\n",
    "        self.base_url = 'https://disclosure.edinet-fsa.go.jp/api/v1/documents'\n",
    "        self.out_of_since = False\n",
    "        self.since = since\n",
    "        self.until = until\n",
    "        self.file_info_str = since.strftime( '_%y%m%d_' ) + until.strftime( '%y%m%d' )\n",
    "        self.file_name = f'dat_download{ self.file_info_str }.csv'\n",
    "        self.base_path = f'{ os.getcwd() if base_dir==None else base_dir }'\n",
    "\n",
    "    def __get_link_info_str( self ,datetime ) :\n",
    "        str_datetime = datetime.strftime( '%Y-%m-%d' )\n",
    "        params = { \"date\" : str_datetime ,\"type\" : 2 }\n",
    "        count ,retry = 0 ,3\n",
    "        while True:\n",
    "            try :\n",
    "                response = requests.get( f'{ self.base_url }.json' ,params=params ,verify=False )\n",
    "                return response.text\n",
    "            except Exception :\n",
    "                print( f'{str_datetime} のアクセスに失敗しました。[ {count} ]' )\n",
    "                if count < retry :\n",
    "                    count += 1\n",
    "                    time.sleep( 3 )\n",
    "                    continue\n",
    "                else : raise\n",
    "\n",
    "    def __parse_json( self ,string ) :\n",
    "        res_dict = json.loads( string )\n",
    "        return res_dict[\"results\"]\n",
    "\n",
    "    def __get_link( self ,target_list ) :\n",
    "        edinet_dict = {}\n",
    "        for target_dict in target_list :\n",
    "            title = f'{ target_dict[\"filerName\"] } { target_dict[\"docDescription\"] }'\n",
    "            if not self.__is_yuho( title ) : continue\n",
    "            docID = target_dict[\"docID\"]\n",
    "            url = f'{ self.base_url }/{ docID }'\n",
    "            edinet_code = target_dict['edinetCode']\n",
    "            updated = target_dict['submitDateTime']\n",
    "            edinet_dict[ docID ] = { 'id':docID ,'title':title ,'url':url ,'code':edinet_code ,'update':updated }\n",
    "        return edinet_dict\n",
    "\n",
    "    def __is_yuho( self ,title ) :\n",
    "        if all( ( s in str( title ) ) for s in [ '有価証券報告書' ,'株式会社' ] ) and '受益証券' not in str( title ) :\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def __dump_file( self ,result_dict ) :\n",
    "        with open( os.path.join( self.base_path ,self.file_name ) ,'w' ,encoding=self.encode_type ) as of :\n",
    "            writer = csv.DictWriter( of ,self.csv_tag ,lineterminator='\\n' )\n",
    "            writer.writeheader()\n",
    "            for key in result_dict : writer.writerow( result_dict[ key ] )\n",
    "\n",
    "    def create_xbrl_url_csv( self ) :\n",
    "        print( f'since: { self.since.strftime( \"%Y-%m-%d\" ) } ,until: { self.until.strftime( \"%Y-%m-%d\" ) } ({ self.file_info_str })' )\n",
    "        target_date ,result_dict = self.since ,{}\n",
    "        while True :\n",
    "            print( f'date { target_date.strftime( \"%Y-%m-%d\" ) }, loading...' )\n",
    "            response_string = self.__get_link_info_str( target_date )\n",
    "            target_list = self.__parse_json( response_string )\n",
    "            info_dict = self.__get_link( target_list )\n",
    "            result_dict.update( info_dict )\n",
    "            time.sleep( self.wait_time )\n",
    "            target_date = target_date + timedelta( days=1 )\n",
    "            if target_date > self.until : break\n",
    "        self.__dump_file( result_dict )\n",
    "        print( 'complete a download!!' )\n",
    "\n",
    "def edinet_operator( since ,until ,base_dir=None ) :\n",
    "    edinet_catcher = catcher( since ,until ,base_dir )\n",
    "    edinet_catcher.create_xbrl_url_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1e64f4-f790-475f-bb20-ca7adcb6e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "since = datetime.strptime('2020-06-01' ,'%Y-%m-%d')\n",
    "until = datetime.strptime('2020-06-02' ,'%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58ed3f7-a2a1-4d01-a025-e70567b7f568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 6, 1, 0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edinet_operator( since ,until ,base_dir=BASE_DIR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60332b91-234a-4fe3-967a-1d26d07e978c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
